{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "trainModel.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOW3BKxX6eZoCZoZRWQhA+8",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SparkyRobin/NEA/blob/master/trainModel.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "70x-xh-lQQ0J"
      },
      "source": [
        "import yfinance as yf\n",
        "import pandas as pd\n",
        "from sklearn import preprocessing\n",
        "import re\n",
        "\n",
        "pd.options.mode.chained_assignment = None  # default='warn'\n",
        "\n",
        "tickers = [\"^NDXT\", \"MSFT\", \"AAPL\", \"FB\", \"AMZN\", \"GOOGL\"] #Will collect data for these tickers\n",
        "samplePeriod = \"60d\" #length of time historic data gathered over\n",
        "sampleInterval = \"1h\" #interval historic data gathered at\n",
        "predictTime = 1 #how many hours ahead it will predict\n",
        "splitPerc = 0.8 #percentage split training to validation data\n",
        "\n",
        "hist = pd.DataFrame()\n",
        "\n",
        "def increase(current, future):\n",
        "    if future > current:\n",
        "        return 1\n",
        "    else:\n",
        "        return 0\n",
        "\n",
        "#data is a pandas dataframe\n",
        "#lents default to 30, but can be changed when called\n",
        "def process(data, lents = 30):\n",
        "    for col in data.columns:\n",
        "\n",
        "        #delete future price as irrelevant\n",
        "        if re.search(\"._future$\", str(col)):\n",
        "            data = data.drop(columns = str(col))\n",
        "\n",
        "        #normalises data not already in normalised format.\n",
        "        elif not re.search(\"._increase$\", str(col)):\n",
        "            if sum(data[col].values) != 0:\n",
        "                data[col] = data[col].pct_change()\n",
        "                data[col].dropna(inplace = True)\n",
        "                data[col] = preprocessing.scale(data[col].values)\n",
        "\n",
        "            #drops columns where all values are 0, as these are indexes which have no market volume\n",
        "            else:\n",
        "                data = data.drop(columns = str(col))\n",
        "    data.dropna(inplace = True)\n",
        "\n",
        "    xseries = []; yseries = []\n",
        "    i=0\n",
        "    while i + lents < int(list(data.shape)[0]):\n",
        "        xsubseries = []; ysubseries = []\n",
        "        for col in data.columns:\n",
        "            xsubseries.append(data[col].values[i:i+lents-1])\n",
        "            ysubseries.append(data[col].values[i+lents])\n",
        "        xseries.append(xsubseries)\n",
        "        yseries.append(ysubseries)\n",
        "        i += 1\n",
        "    return xseries, yseries\n",
        "\n",
        "def model(features, labels):\n",
        "    \n",
        "\n",
        "#collect close prices and volumes for each of ticker into one dataframe\n",
        "for ticker in tickers:\n",
        "    sTicker = yf.Ticker(ticker)\n",
        "    history = sTicker.history(period = f\"{samplePeriod}\", interval = f\"{sampleInterval}\")\n",
        "    history.rename(columns = {\"Close\":f\"{ticker}_close\", \"Volume\":f\"{ticker}_volume\"}, inplace = True)\n",
        "    if len(hist) == 0:\n",
        "        hist = history[[f\"{ticker}_close\", f\"{ticker}_volume\"]]\n",
        "    else:\n",
        "        hist = hist.join(history[[f\"{ticker}_close\", f\"{ticker}_volume\"]])\n",
        "\n",
        "    #adding new columns for each stock for if price increases over predictTime intervals\n",
        "    tempFuture = history[f\"{ticker}_close\"].shift(-predictTime)\n",
        "    tempDF = pd.DataFrame(data = {f\"{ticker}_future\" : history[f\"{ticker}_close\"].shift(-predictTime), f\"{ticker}_increase\" : list(map(increase, history[f\"{ticker}_close\"], tempFuture))})\n",
        "    hist = hist.join(tempDF)\n",
        "    del tempDF\n",
        "\n",
        "hist.dropna(inplace = True) #remove all rows with NaN\n",
        "\n",
        "#split all into training and validation data\n",
        "allLen = int(list(hist.shape)[0])\n",
        "split = int((allLen*splitPerc)//1)\n",
        "allTrain = hist.head(split)\n",
        "allVal = hist.tail(allLen - split)\n",
        "\n",
        "#processing training and validation data\n",
        "trainX, trainY = process(allTrain) ; valX, valY = process(allVal)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}